# Blind Dungeon

An AI-powered, voice-controlled dungeon crawler where you navigate entirely through speech and audio narration.

Built for the [Mistral Worldwide Hackathon](https://mistral.ai) (Feb 28 – Mar 1, 2026).

---

## Overview

Blind Dungeon puts you inside a dark, interconnected dungeon with one rule: **you can't see anything**. You hold Space to speak your commands, and the dungeon speaks back — describing your surroundings, what you've picked up, and the chaos of combat — all narrated in real time by AI.

The core loop:
1. Hold **Space** and speak a command (e.g. *"go north"*, *"pick up the sword"*, *"attack with the axe"*)
2. Mistral parses your intent and generates atmospheric narration
3. ElevenLabs voices the narration aloud
4. Navigate rooms, collect items, fight monsters, and escape the dungeon

---

## Features

- **Voice-controlled gameplay** — hold-to-talk mechanic with real-time transcription via ElevenLabs Scribe v2
- **AI narration** — every room entry, item pickup, and combat exchange is narrated by Mistral LLM in a dark fantasy tone
- **Structured intent parsing** — Mistral extracts actions (move, attack, pickup) from freeform speech using structured output
- **Combat system** — boss room with HP tracking, weapon-based attacks, and skill-based enemy counterattacks
- **Item & inventory system** — pick up weapons, armor, potions, and keys; equip gear across 7 equipment slots
- **Roaming monsters** — enemies move between rooms autonomously and can ambush you mid-exploration
- **Atmospheric audio** — background music per room type (home, normal, boss, exit) with combat sound stingers
- **Persistent state** — game saves to JSON and resumes where you left off

---

## Tech Stack

| Layer | Technology |
|---|---|
| Language | Python 3.11+ |
| UI | PyQt6 (portrait mobile-style layout) |
| LLM (narration) | Mistral — `mistral-large-latest` |
| LLM (intent parsing) | Mistral — `ministral-8b-latest` with structured output |
| Text-to-speech | ElevenLabs — `eleven_multilingual_v2` |
| Speech-to-text | ElevenLabs Scribe v2 Realtime (WebSocket) |
| Audio playback | pygame |
| Microphone capture | pyaudio |
| Data validation | Pydantic |

---

## How We Use Mistral and ElevenLabs

### Mistral

**Narration (mistral-large-latest)**
Every game event — entering a room, picking up an item, winning a fight, dying — triggers a call to Mistral. The model generates a 1–2 sentence atmospheric narration given the current game context (room name, exits, items, combat stats). All prompts are engineered to keep the tone dark, concise, and immersive.

**Intent Parsing (ministral-8b-latest)**
When a player speaks a command, the transcript goes through `IntentParser`, which calls Mistral with a Pydantic response schema. The model returns a structured JSON object — `{ action: "move", direction: "north" }` or `{ action: "attack", weapon: "iron sword" }` — making player input deterministic and low-latency.

```
Player says: "I want to go north"
  → IntentParser.parse() → Mistral structured output
  → IntentAction(action="move", direction="north")
  → GameController handles move, triggers narration
```

### ElevenLabs

**Text-to-Speech**
All narration text generated by Mistral is piped to ElevenLabs TTS (`eleven_multilingual_v2`, George voice). The audio is saved as MP3 and played via pygame, making the narration fully voiced with a consistent dungeon-master persona.

**Real-time Speech-to-Text (Scribe v2)**
When the player holds Space, a WebSocket connection opens to ElevenLabs Scribe v2. Audio chunks (PCM 16-bit mono, 16kHz) stream in real time, with partial transcripts shown live in the UI. The final transcript is emitted when Space is released, feeding into intent parsing.

```
Hold Space → mic stream → ElevenLabs WebSocket → partial transcripts (live)
Release Space → final transcript → IntentParser → game action
```

---

## Quick Start

**Prerequisites**: Python 3.11+, a working microphone

### 1. Clone and set up environment

```bash
git clone <repo-url>
cd mistral-hackathon

python -m venv env
source env/bin/activate       # Windows: env\Scripts\activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure API keys

```bash
cp .env.example .env
```

Edit `.env` and fill in your keys:

```env
MISTRAL_API_KEY=your_mistral_key
ELEVENLABS_API_KEY=your_elevenlabs_key
```

### 4. Run the game

```bash
python main.py
```

Hold **Space** to speak. Release to send your command.

---

## Project Structure

```
mistral-hackathon/
├── main.py                  # Entry point
├── config.py                # Models, audio settings, UI config
├── requirements.txt
│
├── ai/
│   ├── mistral_client.py    # Mistral SDK wrapper (chat + structured output)
│   ├── narrator.py          # Chains Mistral LLM → ElevenLabs TTS
│   ├── intent_parser.py     # Parses voice commands into structured actions
│   ├── tts_client.py        # TTS abstraction (ElevenLabs default)
│   ├── stt_client.py        # STT abstraction (ElevenLabs Scribe v2 active)
│   └── prompts.py           # All LLM prompt templates
│
├── game/
│   ├── game_controller.py   # Central orchestrator (state, AI, workers, signals)
│   ├── game_state.py        # Player/world state, JSON persistence
│   ├── dungeon_map.py       # Room graph and exit validation
│   ├── combat.py            # Combat resolver
│   └── monster_ai.py        # Roaming monster movement logic
│
├── ui/
│   ├── main_window.py       # Root QMainWindow
│   ├── game_view.py         # Room image, narration text, inventory UI
│   └── signals.py           # Central Qt signal bus
│
├── audio/
│   ├── audio_manager.py     # pygame.mixer wrapper
│   └── bg/                  # Background music per room type
│
├── data/
│   ├── items.json           # Weapons, armor, potions
│   ├── bosses.json          # Boss definitions
│   └── monsters.json        # Roaming monster definitions
│
├── maps/
│   └── dungeon_map.json     # Room layout, exits, boss placement
│
└── assets/                  # Images, icons, monster art
```

---

## Controls

| Input | Action |
|---|---|
| Hold **Space** | Record voice command |
| Release **Space** | Send command |

### Voice Commands

| Say | Effect |
|---|---|
| *"go north / south / east / west"* | Move between rooms |
| *"pick up the sword"* | Pick up an item |
| *"attack with the axe"* | Attack in combat |
| *"drink the potion"* | Consume a health potion |
